# 神经网络

因为异或、圆形分布的数据无法用线性分类器解决，第一种解决方案是将非线性的数据线性化，提取更高级的特征，第二种办法就是引入非线性的因素。人们想到在线性分类器上加入非线性的因素，使其能够对非线性的数据进行学习，变成非线性的模型，所以提出了神经网络的方法。

神经网络模型模拟的是动物和人的大脑的工作，对这个过程进行建模，得到在数学上的表达可以等价为:

![image-20220420140144415](src/04.神经网络/image-20220420140144415.png)

多个神经元堆叠：

![image-20220420140431148](src/04.神经网络/image-20220420140431148.png)



## 感知机（Perceptrons / Fully-Connected Networks）

激活函数：

因为有非线性激活函数的存在，导致分类器的输出变成一个非线性的输出。给神经网络带来了模型上的非线性。常见的激活函数有：

![image-20220420194049166](src/04.神经网络/image-20220420194049166.png)



一层里面每一个神经元都与前一层的所有神经元进行连接。

![image-20220420194257021](src/04.神经网络/image-20220420194257021.png)

通过多次非线性的激活使得线性函数能够拟合非线性的数据。本质上还是以线性函数为基础传递和学习权重。在没有使用激活函数的情况下，通常的传播通过多次迭代线性函数，每一次迭代经过一个激活函数使其变得非线性，实现数据的前向传播。
$$
f = W_1x+b \\
f = W_2\max(0, W_1x+b) \\
f = W_3\max(0, W_2\max(0, W_1x+b)) \\
\vdots
$$
使用图示可以这么表示：

![image-20220424201101723](src/04.神经网络/image-20220424201101723.png)



## 反向传播

反向传播是神经网络训练的方法，根据前向传播的结果，使用链式法则反向求解各个计算节点的梯度，用梯度来更新所输入的权重。

反向传播的基本操作，

深度越深，特征能力表示越强，但是也越容易过拟合。

深度和宽度的选择原则，只有一个隐含层，只要神经元个数足够多，能够解决任何问题。

